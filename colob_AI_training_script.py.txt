import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import zipfile
import shutil

# --- CONFIGURATION ---
# The name of the ZIP file you upload to Colab containing your labeled images
ZIP_FILE_NAME = 'training_data.zip' 
# The folder created when you unzip the data
DATA_DIR = 'training_data'
# The size used in your preprocessing script
IMAGE_SIZE = (224, 224) 
# Batch size for training (adjust based on Colab's memory/speed)
BATCH_SIZE = 32
# How many times to loop over the entire dataset (5-10 is usually enough for transfer learning)
EPOCHS = 8 
# ---------------------

def run_training():
    """Main function to handle data loading, model definition, training, and export."""
    print("--- Starting Colab Training Pipeline ---")

    # 1. UNZIP DATA
    if not os.path.exists(ZIP_FILE_NAME):
        print(f"FATAL: {ZIP_FILE_NAME} not found. Please upload your zipped data to Colab and rename it if necessary.")
        return

    print(f"1. Unzipping {ZIP_FILE_NAME}...")
    try:
        with zipfile.ZipFile(ZIP_FILE_NAME, 'r') as zip_ref:
            zip_ref.extractall('.')
    except Exception as e:
        print(f"Error during unzipping: {e}")
        return

    if not os.path.exists(DATA_DIR):
        print(f"FATAL: Extracted directory '{DATA_DIR}' not found. Check the zip file structure.")
        return

    # 2. DATA GENERATOR SETUP
    datagen = ImageDataGenerator(
        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,
    )

    print("2. Setting up data generators...")
    train_generator = datagen.flow_from_directory(
        DATA_DIR,
        target_size=IMAGE_SIZE,
        batch_size=BATCH_SIZE,
        class_mode='categorical'
    )
    
    num_classes = train_generator.num_classes
    class_names = list(train_generator.class_indices.keys())
    print(f"Detected {num_classes} classes: {class_names}")

    # 3. MODEL DEFINITION (Transfer Learning with MobileNetV2)
    print("3. Defining MobileNetV2 Transfer Learning Model...")
    
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),
        include_top=False,
        weights='imagenet'
    )
    
    base_model.trainable = False
    
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(num_classes, activation='softmax')
    ])

    # 4. MODEL COMPILATION AND TRAINING
    print("4. Compiling and training model...")
    model.compile(
        optimizer=tf.keras.optimizers.Adam(),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    model.fit(
        train_generator,
        epochs=EPOCHS
    )
    
    # 5. EXPORT THE FINAL MODEL (CRITICAL: Using TFLite Converter for stability)
    print("5. Training complete. Converting and exporting model to TFLite format...")
    
    # Convert the Keras model to a TFLite model
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    
    # Save the TFLite model
    output_model_path = 'allsky_cloud_detector_final.tflite'
    with open(output_model_path, 'wb') as f:
        f.write(tflite_model)
    
    # 6. EXPORT THE LABELS.TXT FILE
    output_labels_path = 'labels.txt'
    with open(output_labels_path, 'w') as f:
        for i, name in enumerate(class_names):
            # Ensure labels are saved in the format the predictor expects (e.g., "0 Clear")
            f.write(f"{i} {name}\n")

    print("\n--- Training Successful ---")
    print(f"Download these two files from the Colab file browser:")
    print(f" - Model: {output_model_path}")
    print(f" - Labels: {output_labels_path}")
    
    # 7. CLEAN UP
    shutil.rmtree(DATA_DIR, ignore_errors=True)

if __name__ == '__main__':
    run_training()